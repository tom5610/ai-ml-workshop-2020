{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Sentiment Analysis on Calls Recording\n",
    "\n",
    "In the notebook, we will be experimenting how to trigger a serverless-based workflow to do sentiment analysis on calls recordings. The use case is based on using Amazon Connect for call center setup and forwarding call recordings to a S3 bucket to trigger sentiment analysis of the call conversation. \n",
    "\n",
    "In the lab, we won't cover Amazon Connect setup, but will focus on how to use serverless-based architecture to manager the how process, including:\n",
    "* Using AWS Lambda function to split audio file\n",
    "* Using Amazon Transcribe to do speech recognition with Step Functions orchestration (coverting voice to text)\n",
    "* Using Amazon Comprehend to do sentiment analysis on the text content\n",
    "\n",
    "## Architecture Design\n",
    "\n",
    "![architecture diagram](./images/sentiment-analysis-on-calls-recording.png)\n",
    "\n",
    "## To Experiment\n",
    "\n",
    "* To prepare a `*.wav` format file and upload to target S3 bucket to trigger the whole process\n",
    "* To review the text content and compare to the origin\n",
    "* To review the sentment analysis result \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "ssm = boto3.client('ssm')\n",
    "\n",
    "response = ssm.get_parameter(Name = \"/aiml-lab/sentiment_analysis_s3_bucket_name\")\n",
    "bucket_name = response['Parameter']['Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_transcript = 'connect'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Trigger the Process\n",
    "\n",
    "We will be using **Open Speech Repository** [American English - Harvard Sentences](http://www.voiptroubleshooter.com/open_speech/american.html) as testing examples. While checking the text result, you may refer to [Harvard Sentences Text](http://www.cs.columbia.edu/~hgs/audio/harvard.html).\n",
    "\n",
    "Meanwhile, you can also use your own voice record for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voice file collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_file_name = 'OSR_us_000_0010_8k.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-12-06 11:21:45--  http://www.voiptroubleshooter.com/open_speech/american/OSR_us_000_0010_8k.wav\n",
      "Resolving www.voiptroubleshooter.com (www.voiptroubleshooter.com)... 162.241.218.124\n",
      "Connecting to www.voiptroubleshooter.com (www.voiptroubleshooter.com)|162.241.218.124|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 538014 (525K) [audio/x-wav]\n",
      "Saving to: ‘OSR_us_000_0010_8k.wav’\n",
      "\n",
      "OSR_us_000_0010_8k. 100%[===================>] 525.40K  2.16MB/s    in 0.2s    \n",
      "\n",
      "2020-12-06 11:21:45 (2.16 MB/s) - ‘OSR_us_000_0010_8k.wav’ saved [538014/538014]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.voiptroubleshooter.com/open_speech/american/$voice_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "contact_id = datetime.now().strftime(\"%y%m%d-%H%M\")\n",
    "\n",
    "s3.upload_file(\n",
    "    f'./{voice_file_name}', \n",
    "    bucket_name, \n",
    "    f'{prefix_transcript}/{voice_file_name}',\n",
    "    ExtraArgs={ \"Metadata\": { \"contact-id\" : contact_id }}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may wait a couple of minutes and run below cell multiple times until you can see examples like:\n",
    "\n",
    "```\n",
    "2020-12-06 11:39:37       2881 comprehend/20120X-####-Customer-comprehend.json\n",
    "2020-12-06 11:35:46     538014 connect/OSR_us_000_0010_8k.wav\n",
    "2020-12-06 11:38:56     538014 recordings/Customer/2020/12/20120X-####-Customer.wav\n",
    "2020-12-06 11:39:35      11625 transcripts/20120X-####-Customer.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-06 11:39:37       2881 comprehend/201206-1135-Customer-comprehend.json\n",
      "2020-12-06 11:35:46     538014 connect/OSR_us_000_0010_8k.wav\n",
      "2020-12-06 11:38:56     538014 recordings/Customer/2020/12/201206-1135-Customer.wav\n",
      "2020-12-06 11:39:35      11625 transcripts/201206-1135-Customer.json\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://$bucket_name --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once analysis file arrives at 'comprehend' folder, let's download it to have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please update the file key based on the actual file.\n",
    "s3_resource = boto3.resource('s3')\n",
    "local_result_file = 'result.json'\n",
    "comprehend_result_file_key = 'comprehend/201206-1135-Customer-comprehend.json'\n",
    "s3_resource.Bucket(bucket_name).download_file(comprehend_result_file_key, local_result_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>talker</th>\n",
       "      <th>key</th>\n",
       "      <th>contactId</th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Entities</th>\n",
       "      <th>KeyPhrases</th>\n",
       "      <th>DominantLanguage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Customer</td>\n",
       "      <td>201206-1135-Customer</td>\n",
       "      <td>201206-1135</td>\n",
       "      <td>birch canoe slid on the smooth planks glue the sheet to the dark blue background. It is easy to tell the depth over well these days. Chicken legs a rare dish. Rice is often served in round balls. The juice of lemons makes fine punch. The box was torn beside the park truck. The hogs are fit. Chop corn and garbage. Four hours of study work faced us. A. Large size and stockings is hard to sell.</td>\n",
       "      <td>{'Index': 0, 'Sentiment': 'POSITIVE', 'SentimentScore': {'Positive': 0.502876281738281, 'Negative': 0.29806569218635504, 'Neutral': 0.12519305944442702, 'Mixed': 0.073864996433258}}</td>\n",
       "      <td>{'Index': 0, 'Entities': [{'Score': 0.924670219421386, 'Type': 'QUANTITY', 'Text': 'Four hours', 'BeginOffset': 315, 'EndOffset': 325}]}</td>\n",
       "      <td>{'Index': 0, 'KeyPhrases': [{'Score': 0.9048020243644711, 'Text': 'birch canoe', 'BeginOffset': 0, 'EndOffset': 11}, {'Score': 0.9999999403953551, 'Text': 'the smooth planks', 'BeginOffset': 20, 'EndOffset': 37}, {'Score': 0.9999844431877131, 'Text': 'the sheet', 'BeginOffset': 43, 'EndOffset': 52}, {'Score': 1.0, 'Text': 'the dark blue background', 'BeginOffset': 56, 'EndOffset': 80}, {'Score': 1.0, 'Text': 'the depth', 'BeginOffset': 101, 'EndOffset': 110}, {'Score': 0.9515584111213681, 'Text': 'well these days', 'BeginOffset': 116, 'EndOffset': 131}, {'Score': 0.9999622106552121, 'Text': 'Chicken', 'BeginOffset': 133, 'EndOffset': 140}, {'Score': 0.9991579055786131, 'Text': 'a rare dish', 'BeginOffset': 146, 'EndOffset': 157}, {'Score': 0.999982476234436, 'Text': 'Rice', 'BeginOffset': 159, 'EndOffset': 163}, {'Score': 0.9999395012855531, 'Text': 'round balls', 'BeginOffset': 183, 'EndOffset': 194}, {'Score': 0.9999971985816951, 'Text': 'The juice', 'BeginOffset': 196, 'EndOffset': 205}, {'Score': 0.9999996423721311, 'Text': 'lemons', 'BeginOffset': 209, 'EndOffset': 215}, {'Score': 0.999970912933349, 'Text': 'fine punch', 'BeginOffset': 222, 'EndOffset': 232}, {'Score': 0.999996423721313, 'Text': 'The box', 'BeginOffset': 234, 'EndOffset': 241}, {'Score': 0.99999588727951, 'Text': 'the park truck', 'BeginOffset': 258, 'EndOffset': 272}, {'Score': 0.9998894929885861, 'Text': 'The hogs', 'BeginOffset': 274, 'EndOffset': 282}, {'Score': 0.973886907100677, 'Text': 'corn and garbage', 'BeginOffset': 297, 'EndOffset': 313}, {'Score': 0.9999996423721311, 'Text': 'Four hours', 'BeginOffset': 315, 'EndOffset': 325}, {'Score': 0.9953986406326291, 'Text': 'study work', 'BeginOffset': 329, 'EndOffset': 339}, {'Score': 0.918866991996765, 'Text': 'A. Large size', 'BeginOffset': 350, 'EndOffset': 363}, {'Score': 0.8826413750648491, 'Text': 'stockings', 'BeginOffset': 368, 'EndOffset': 377}]}</td>\n",
       "      <td>{'Index': 0, 'Languages': [{'LanguageCode': 'en', 'Score': 0.9954248666763301}]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     talker                   key    contactId  \\\n",
       "0  Customer  201206-1135-Customer  201206-1135   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                         text  \\\n",
       "0  birch canoe slid on the smooth planks glue the sheet to the dark blue background. It is easy to tell the depth over well these days. Chicken legs a rare dish. Rice is often served in round balls. The juice of lemons makes fine punch. The box was torn beside the park truck. The hogs are fit. Chop corn and garbage. Four hours of study work faced us. A. Large size and stockings is hard to sell.   \n",
       "\n",
       "                                                                                                                                                                               Sentiment  \\\n",
       "0  {'Index': 0, 'Sentiment': 'POSITIVE', 'SentimentScore': {'Positive': 0.502876281738281, 'Negative': 0.29806569218635504, 'Neutral': 0.12519305944442702, 'Mixed': 0.073864996433258}}   \n",
       "\n",
       "                                                                                                                                   Entities  \\\n",
       "0  {'Index': 0, 'Entities': [{'Score': 0.924670219421386, 'Type': 'QUANTITY', 'Text': 'Four hours', 'BeginOffset': 315, 'EndOffset': 325}]}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  KeyPhrases  \\\n",
       "0  {'Index': 0, 'KeyPhrases': [{'Score': 0.9048020243644711, 'Text': 'birch canoe', 'BeginOffset': 0, 'EndOffset': 11}, {'Score': 0.9999999403953551, 'Text': 'the smooth planks', 'BeginOffset': 20, 'EndOffset': 37}, {'Score': 0.9999844431877131, 'Text': 'the sheet', 'BeginOffset': 43, 'EndOffset': 52}, {'Score': 1.0, 'Text': 'the dark blue background', 'BeginOffset': 56, 'EndOffset': 80}, {'Score': 1.0, 'Text': 'the depth', 'BeginOffset': 101, 'EndOffset': 110}, {'Score': 0.9515584111213681, 'Text': 'well these days', 'BeginOffset': 116, 'EndOffset': 131}, {'Score': 0.9999622106552121, 'Text': 'Chicken', 'BeginOffset': 133, 'EndOffset': 140}, {'Score': 0.9991579055786131, 'Text': 'a rare dish', 'BeginOffset': 146, 'EndOffset': 157}, {'Score': 0.999982476234436, 'Text': 'Rice', 'BeginOffset': 159, 'EndOffset': 163}, {'Score': 0.9999395012855531, 'Text': 'round balls', 'BeginOffset': 183, 'EndOffset': 194}, {'Score': 0.9999971985816951, 'Text': 'The juice', 'BeginOffset': 196, 'EndOffset': 205}, {'Score': 0.9999996423721311, 'Text': 'lemons', 'BeginOffset': 209, 'EndOffset': 215}, {'Score': 0.999970912933349, 'Text': 'fine punch', 'BeginOffset': 222, 'EndOffset': 232}, {'Score': 0.999996423721313, 'Text': 'The box', 'BeginOffset': 234, 'EndOffset': 241}, {'Score': 0.99999588727951, 'Text': 'the park truck', 'BeginOffset': 258, 'EndOffset': 272}, {'Score': 0.9998894929885861, 'Text': 'The hogs', 'BeginOffset': 274, 'EndOffset': 282}, {'Score': 0.973886907100677, 'Text': 'corn and garbage', 'BeginOffset': 297, 'EndOffset': 313}, {'Score': 0.9999996423721311, 'Text': 'Four hours', 'BeginOffset': 315, 'EndOffset': 325}, {'Score': 0.9953986406326291, 'Text': 'study work', 'BeginOffset': 329, 'EndOffset': 339}, {'Score': 0.918866991996765, 'Text': 'A. Large size', 'BeginOffset': 350, 'EndOffset': 363}, {'Score': 0.8826413750648491, 'Text': 'stockings', 'BeginOffset': 368, 'EndOffset': 377}]}   \n",
       "\n",
       "                                                                   DominantLanguage  \n",
       "0  {'Index': 0, 'Languages': [{'LanguageCode': 'en', 'Score': 0.9954248666763301}]}  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 0)  \n",
    "df = pd.read_json(local_result_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under the Hood\n",
    "\n",
    "Now, we are going to disclose how the whole process work together. Before continue reading, would you want to check by your own? \n",
    "\n",
    "If **YES**, please refer to [template.yaml](./template.yaml) file to understand the stack structure; and also, please refer to  [code folder](./code) and below services console for more detail:\n",
    "* [AWS Lambda](https://console.aws.amazon.com/lambda/home?region=us-east-1#/functions)\n",
    "* [S3](https://s3.console.aws.amazon.com/s3/home?region=us-east-1)\n",
    "* [AWS Step Functions](https://console.aws.amazon.com/states/home?region=us-east-1#/statemachines)\n",
    "* [AWS Glue](https://console.aws.amazon.com/glue/home?region=us-east-1#catalog:tab=databases)\n",
    "\n",
    "> Please scroll down to check 'Demystifying the Process' section when you are ready!\n",
    "\n",
    "![Discovery](./images/discovery-unsplash.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demystifying the Process\n",
    "\n",
    "* Once voice file is uploaded to folder '/connect' with meta data 'connect-id' = ###, lambda function [split_audio_lambda](https://console.aws.amazon.com/lambda/home?region=us-east-1#/functions/split_audio_lambda?tab=configuration) is triggered to split the voice file (customer vs agent) and save the result files into folder '/recordings'\n",
    "* Once files arrive at folder '/recordings', lambda function [execute_transcription_state_machine](https://console.aws.amazon.com/lambda/home?region=us-east-1#/functions/execute_transcription_state_machine?tab=configuration) will be triggered to execute Step Functions [State Machines](https://console.aws.amazon.com/states/home?region=us-east-1#/statemachines)\n",
    " * Lambda function [submit_transcribe_job](https://console.aws.amazon.com/lambda/home?region=us-east-1#/functions/submit_transcribe_job?tab=configuration) will be executed in state machiine. \n",
    " * Once Transcribe job is done, Lambda function [save_transcription_to_s3](https://console.aws.amazon.com/lambda/home?region=us-east-1#/functions/save_transcription_to_s3?tab=configuration) will be executed to save the transcription to folder '/transcripts'\n",
    "* Once file arrives at '/transcripts', lambda function [comprehend_transcript_lambda](https://console.aws.amazon.com/lambda/home?region=us-east-1#/functions/comprehend_transcript_lambda?tab=configuration) will be executed to process below NLP analysis and save result in folder '/comprehend'\n",
    " * Sentiment\n",
    " * Entities\n",
    " * KeyPhrases\n",
    " * DominantLanguage\n",
    "* Last but not least, comprehend analysis result files can be searched with Athena (SQL-like queries) given related [Glue Database](https://console.aws.amazon.com/glue/home?region=us-east-1#catalog:tab=databases) & Table are created to parse the files.\n",
    " * [Try Athena Queries](https://console.aws.amazon.com/athena/home?force&region=us-east-1#query)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
