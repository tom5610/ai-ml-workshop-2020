{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Sentiment Analysis on Calls Recording\n",
    "\n",
    "In the notebook, we will be experimenting how to trigger a serverless-based workflow to do sentiment analysis on calls recordings. The use case is based on using Amazon Connect for call center setup and forwarding call recordings to a S3 bucket to trigger sentiment analysis of the call conversation. \n",
    "\n",
    "In the lab, we won't cover Amazon Connect setup, but will focus on how to use serverless-based architecture to manager the how process, including:\n",
    "* Using AWS Lambda function to split audio file\n",
    "* Using Amazon Transcribe to do speech recognition with Step Functions orchestration (coverting voice to text)\n",
    "* Using Amazon Comprehend to do sentiment analysis on the text content\n",
    "\n",
    "## Architecture Design\n",
    "\n",
    "![architecture diagram](./images/sentiment-analysis-on-calls-recording.png)\n",
    "\n",
    "## To Experiment\n",
    "\n",
    "* To prepare a `*.wav` format file and upload to target S3 bucket to trigger the whole process\n",
    "* To review the text content and compare to the origin\n",
    "* To review the sentment analysis result \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "ssm = boto3.client('ssm')\n",
    "\n",
    "response = ssm.get_parameter(Name = \"/aiml-lab/sentiment_analysis_s3_bucket_name\")\n",
    "bucket_name = response['Parameter']['Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_transcript = 'connect'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Trigger the Process\n",
    "\n",
    "We will be using **Open Speech Repository** [American English - Harvard Sentences](http://www.voiptroubleshooter.com/open_speech/american.html) as testing examples. While checking the text result, you may refer to [Harvard Sentences Text](http://www.cs.columbia.edu/~hgs/audio/harvard.html).\n",
    "\n",
    "Meanwhile, you can also use your own voice record for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voice file collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_file_name = 'OSR_us_000_0010_8k.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://www.voiptroubleshooter.com/open_speech/american/$voice_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "contact_id = datetime.now().strftime(\"%y%m%d-%H%M\")\n",
    "\n",
    "s3.upload_file(\n",
    "    f'./{voice_file_name}', \n",
    "    bucket_name, \n",
    "    f'{prefix_transcript}/{voice_file_name}',\n",
    "    ExtraArgs={ \"Metadata\": { \"contact-id\" : contact_id }}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may wait a couple of minutes and run below cell multiple times until you can see examples like:\n",
    "\n",
    "```\n",
    "2020-12-06 11:39:37       2881 comprehend/20120X-####-Customer-comprehend.json\n",
    "2020-12-06 11:35:46     538014 connect/OSR_us_000_0010_8k.wav\n",
    "2020-12-06 11:38:56     538014 recordings/Customer/2020/12/20120X-####-Customer.wav\n",
    "2020-12-06 11:39:35      11625 transcripts/20120X-####-Customer.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls s3://$bucket_name --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once analysis file arrives at 'comprehend' folder, let's download it to have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please update the file key based on the actual file.\n",
    "s3_resource = boto3.resource('s3')\n",
    "local_result_file = 'result.json'\n",
    "comprehend_result_file_key = 'comprehend/201206-1135-Customer-comprehend.json'\n",
    "s3_resource.Bucket(bucket_name).download_file(comprehend_result_file_key, local_result_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 0)  \n",
    "df = pd.read_json(local_result_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under the Hood\n",
    "\n",
    "Now, we are going to disclose how the whole process work together. Before continue reading, would you want to check by your own? \n",
    "\n",
    "If **YES**, please refer to [template.yaml](./template.yaml) file to understand the stack structure; and also, please refer to  [code folder](./code) and below services console for more detail:\n",
    "* [AWS Lambda](https://console.aws.amazon.com/lambda/home?region=us-east-1#/functions)\n",
    "* [S3](https://s3.console.aws.amazon.com/s3/home?region=us-east-1)\n",
    "* [AWS Step Functions](https://console.aws.amazon.com/states/home?region=us-east-1#/statemachines)\n",
    "* [AWS Glue](https://console.aws.amazon.com/glue/home?region=us-east-1#catalog:tab=databases)\n",
    "\n",
    "> Please scroll down to check 'Demystifying the Process' section when you are ready!\n",
    "\n",
    "![Discovery](./images/discovery-unsplash.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demystifying the Process\n",
    "\n",
    "* Once voice file is uploaded to folder '/connect' with meta data 'connect-id' = ###, lambda function [split_audio_lambda](https://console.aws.amazon.com/lambda/home?region=us-east-1#/functions/split_audio_lambda?tab=configuration) is triggered to split the voice file (customer vs agent) and save the result files into folder '/recordings'\n",
    "* Once files arrive at folder '/recordings', lambda function [execute_transcription_state_machine](https://console.aws.amazon.com/lambda/home?region=us-east-1#/functions/execute_transcription_state_machine?tab=configuration) will be triggered to execute Step Functions [State Machines](https://console.aws.amazon.com/states/home?region=us-east-1#/statemachines)\n",
    " * Lambda function [submit_transcribe_job](https://console.aws.amazon.com/lambda/home?region=us-east-1#/functions/submit_transcribe_job?tab=configuration) will be executed in state machiine. \n",
    " * Once Transcribe job is done, Lambda function [save_transcription_to_s3](https://console.aws.amazon.com/lambda/home?region=us-east-1#/functions/save_transcription_to_s3?tab=configuration) will be executed to save the transcription to folder '/transcripts'\n",
    "* Once file arrives at '/transcripts', lambda function [comprehend_transcript_lambda](https://console.aws.amazon.com/lambda/home?region=us-east-1#/functions/comprehend_transcript_lambda?tab=configuration) will be executed to process below NLP analysis and save result in folder '/comprehend'\n",
    " * Sentiment\n",
    " * Entities\n",
    " * KeyPhrases\n",
    " * DominantLanguage\n",
    "* Last but not least, comprehend analysis result files can be searched with Athena (SQL-like queries) given related [Glue Database](https://console.aws.amazon.com/glue/home?region=us-east-1#catalog:tab=databases) & Table are created to parse the files.\n",
    " * [Try Athena Queries](https://console.aws.amazon.com/athena/home?force&region=us-east-1#query)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original Lab\n",
    "\n",
    "To learn more, you may refer to the [original lab](https://master.d167n899s5ufv3.amplifyapp.com/en/600-pipeline.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
